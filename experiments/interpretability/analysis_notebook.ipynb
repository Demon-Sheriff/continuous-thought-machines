{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mechanistic Interpretability of CTM on Maze Navigation\n",
        "\n",
        "## Research Hypothesis\n",
        "\n",
        "The Continuous Thought Machine (CTM) constructs a **\"Virtual Coordinate System\"** dynamically within the Synchronization Matrix ($S_t$) when solving 2D mazes **without positional embeddings**.\n",
        "\n",
        "Specific clusters of neurons likely fire only when the agent \"imagines\" itself at specific $(x,y)$ coordinates in the maze - similar to **Place Cells** in the hippocampus.\n",
        "\n",
        "---\n",
        "\n",
        "## Notebook Overview\n",
        "\n",
        "1. **Setup**: Load model and data\n",
        "2. **Visualization**: Explore internal states across ticks\n",
        "3. **Place Cell Analysis**: Find neurons that correlate with positions\n",
        "4. **Intervention**: Test causal role of position-encoding neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# Add project root to path\n",
        "PROJECT_ROOT = Path.cwd().parent.parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "# Project imports\n",
        "from models.ctm import ContinuousThoughtMachine\n",
        "from data.custom_datasets import MazeImageFolder\n",
        "\n",
        "# Optional wandb\n",
        "try:\n",
        "    import wandb\n",
        "    WANDB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    WANDB_AVAILABLE = False\n",
        "\n",
        "# Plotting settings\n",
        "sns.set_style('darkgrid')\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# Device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    # Model\n",
        "    'checkpoint_path': str(PROJECT_ROOT / 'checkpoints/mazes/ctm_mazeslarge_D=2048_T=75_M=25.pt'),\n",
        "    \n",
        "    # Data\n",
        "    'data_root': str(PROJECT_ROOT / 'data/mazes'),\n",
        "    'maze_size': 'medium',  # 'small', 'medium', or 'large'\n",
        "    'num_samples': 50,\n",
        "    'batch_size': 8,\n",
        "    \n",
        "    # Analysis\n",
        "    'num_top_neurons': 20,\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for k, v in CONFIG.items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Model\n",
        "\n",
        "The CTM architecture for maze solving:\n",
        "- **Backbone**: ResNet-based feature extractor (no positional embeddings!)\n",
        "- **Synapse Model**: U-Net style MLP for cross-neuron communication\n",
        "- **NLMs**: Private MLPs per neuron processing activation history\n",
        "- **Output**: Synchronization-based predictions\n",
        "\n",
        "Key insight: `positional_embedding_type = 'none'` confirms no explicit position info!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(checkpoint_path, device):\n",
        "    \"\"\"Load CTM model from checkpoint.\"\"\"\n",
        "    print(f\"Loading checkpoint: {checkpoint_path}\")\n",
        "    \n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Checkpoint not found: {checkpoint_path}\\n\"\n",
        "            f\"Download from: https://drive.google.com/drive/folders/1vSg8T7FqP-guMDk1LU7_jZaQtXFP9sZg\"\n",
        "        )\n",
        "    \n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "    model_args = checkpoint['args']\n",
        "    \n",
        "    # Handle legacy arguments\n",
        "    if not hasattr(model_args, 'backbone_type'):\n",
        "        model_args.backbone_type = f'{model_args.resnet_type}-{model_args.resnet_feature_scales[-1]}'\n",
        "    if not hasattr(model_args, 'neuron_select_type'):\n",
        "        model_args.neuron_select_type = 'first-last'\n",
        "    if not hasattr(model_args, 'n_random_pairing_self'):\n",
        "        model_args.n_random_pairing_self = 0\n",
        "    \n",
        "    # Print key config\n",
        "    print(f\"\\nModel Configuration:\")\n",
        "    print(f\"  d_model (neurons): {model_args.d_model}\")\n",
        "    print(f\"  iterations (ticks): {model_args.iterations}\")\n",
        "    print(f\"  memory_length: {model_args.memory_length}\")\n",
        "    print(f\"  positional_embedding_type: {model_args.positional_embedding_type}\")\n",
        "    \n",
        "    prediction_reshaper = [model_args.out_dims // 5, 5]\n",
        "    \n",
        "    model = ContinuousThoughtMachine(\n",
        "        iterations=model_args.iterations,\n",
        "        d_model=model_args.d_model,\n",
        "        d_input=model_args.d_input,\n",
        "        heads=model_args.heads,\n",
        "        n_synch_out=model_args.n_synch_out,\n",
        "        n_synch_action=model_args.n_synch_action,\n",
        "        synapse_depth=model_args.synapse_depth,\n",
        "        memory_length=model_args.memory_length,\n",
        "        deep_nlms=model_args.deep_memory,\n",
        "        memory_hidden_dims=model_args.memory_hidden_dims,\n",
        "        do_layernorm_nlm=model_args.do_normalisation,\n",
        "        backbone_type=model_args.backbone_type,\n",
        "        positional_embedding_type=model_args.positional_embedding_type,\n",
        "        out_dims=model_args.out_dims,\n",
        "        prediction_reshaper=prediction_reshaper,\n",
        "        dropout=0,\n",
        "        neuron_select_type=model_args.neuron_select_type,\n",
        "        n_random_pairing_self=model_args.n_random_pairing_self,\n",
        "    ).to(device)\n",
        "    \n",
        "    state_dict_key = 'state_dict' if 'state_dict' in checkpoint else 'model_state_dict'\n",
        "    model.load_state_dict(checkpoint[state_dict_key], strict=False)\n",
        "    model.eval()\n",
        "    \n",
        "    return model, model_args\n",
        "\n",
        "try:\n",
        "    model, model_args = load_model(CONFIG['checkpoint_path'], device)\n",
        "    print(f\"\\n✓ Model loaded successfully with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n✗ {e}\")\n",
        "    model = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Maze Data\n",
        "\n",
        "Maze encoding:\n",
        "- **Red (1,0,0)**: Start position\n",
        "- **Green (0,1,0)**: Goal position\n",
        "- **Black (0,0,0)**: Walls\n",
        "- **White (1,1,1)**: Walkable path\n",
        "\n",
        "Output: Sequence of moves [0=Up, 1=Down, 2=Left, 3=Right, 4=Wait]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_maze_data(data_root, maze_size, num_samples, batch_size):\n",
        "    \"\"\"Load maze dataset.\"\"\"\n",
        "    data_path = f\"{data_root}/{maze_size}/test\"\n",
        "    \n",
        "    if not os.path.exists(data_path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Maze data not found: {data_path}\\n\"\n",
        "            f\"Download from: https://drive.google.com/file/d/1cBgqhaUUtsrll8-o2VY42hPpyBcfFv86/view\"\n",
        "        )\n",
        "    \n",
        "    dataset = MazeImageFolder(\n",
        "        root=data_path,\n",
        "        which_set='test',\n",
        "        maze_route_length=100,\n",
        "        expand_range=True,\n",
        "        trunc=True if num_samples < 1000 else False\n",
        "    )\n",
        "    \n",
        "    if len(dataset) > num_samples:\n",
        "        dataset = torch.utils.data.Subset(dataset, list(range(num_samples)))\n",
        "    \n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
        "    )\n",
        "    \n",
        "    return loader, dataset\n",
        "\n",
        "try:\n",
        "    dataloader, dataset = load_maze_data(\n",
        "        CONFIG['data_root'], CONFIG['maze_size'], \n",
        "        CONFIG['num_samples'], CONFIG['batch_size']\n",
        "    )\n",
        "    print(f\"\\n✓ Loaded {len(dataset)} mazes\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n✗ {e}\")\n",
        "    dataloader = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Sample Maze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if dataloader is not None:\n",
        "    # Get a sample maze\n",
        "    inputs, targets = next(iter(dataloader))\n",
        "    \n",
        "    # Convert from [-1, 1] to [0, 1] for display\n",
        "    maze_img = ((inputs[0].numpy() + 1) / 2).transpose(1, 2, 0)\n",
        "    solution = targets[0].numpy()\n",
        "    \n",
        "    # Find actual path length (before padding)\n",
        "    path_length = (solution != 4).sum()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    # Show maze\n",
        "    axes[0].imshow(maze_img)\n",
        "    axes[0].set_title(f'Maze ({CONFIG[\"maze_size\"]})')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Show solution statistics\n",
        "    move_names = ['Up', 'Down', 'Left', 'Right', 'Wait']\n",
        "    move_counts = [(solution == i).sum() for i in range(5)]\n",
        "    \n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
        "    axes[1].bar(move_names, move_counts, color=colors)\n",
        "    axes[1].set_title(f'Solution Moves (Path length: {path_length})')\n",
        "    axes[1].set_ylabel('Count')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nMaze shape: {maze_img.shape}\")\n",
        "    print(f\"Solution: {solution[:path_length].tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Collect Internal States\n",
        "\n",
        "Run the model with `track=True` to capture:\n",
        "- **Pre-activations** ($a_t$): Input to NLMs\n",
        "- **Post-activations** ($z_t$): Output of NLMs - **KEY for our analysis!**\n",
        "- **Synchronization** ($S_t$): Pairwise neuron correlations\n",
        "- **Attention**: Where the model looks in the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_internal_states(model, dataloader, device, max_batches=None):\n",
        "    \"\"\"Collect internal states from model.\"\"\"\n",
        "    all_states = {\n",
        "        'pre_activations': [],   # (T, B, D) per batch\n",
        "        'post_activations': [],  # (T, B, D) per batch  \n",
        "        'synch_out': [],         # (T, B, S) per batch\n",
        "        'attention': [],         # (T, B, H, Hf, Wf) per batch\n",
        "        'predictions': [],       # (B, out_dims, T) per batch\n",
        "        'mazes': [],             # (B, H, W, 3) per batch\n",
        "        'solutions': [],         # (B, route_len) per batch\n",
        "    }\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(tqdm(dataloader, desc=\"Collecting states\")):\n",
        "            if max_batches and batch_idx >= max_batches:\n",
        "                break\n",
        "                \n",
        "            inputs = inputs.to(device)\n",
        "            \n",
        "            # Run with tracking\n",
        "            results = model(inputs, track=True)\n",
        "            predictions, certainties, (synch_out, synch_action), pre_act, post_act, attention = results\n",
        "            \n",
        "            # Store\n",
        "            all_states['pre_activations'].append(pre_act)\n",
        "            all_states['post_activations'].append(post_act)\n",
        "            all_states['synch_out'].append(synch_out)\n",
        "            all_states['attention'].append(attention)\n",
        "            all_states['predictions'].append(predictions.cpu().numpy())\n",
        "            all_states['mazes'].append(((inputs.cpu().numpy() + 1) / 2).transpose(0, 2, 3, 1))\n",
        "            all_states['solutions'].append(targets.numpy())\n",
        "    \n",
        "    return all_states\n",
        "\n",
        "if model is not None and dataloader is not None:\n",
        "    states = collect_internal_states(model, dataloader, device, max_batches=5)\n",
        "    \n",
        "    # Print shapes\n",
        "    print(\"\\nCollected State Shapes:\")\n",
        "    for key in ['pre_activations', 'post_activations', 'synch_out', 'attention']:\n",
        "        if states[key]:\n",
        "            print(f\"  {key}: {states[key][0].shape} (per batch)\")\n",
        "else:\n",
        "    print(\"Model or data not loaded. Skipping state collection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Neuron Dynamics Across Ticks\n",
        "\n",
        "How do neuron activations evolve as the model \"thinks\" through the maze?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'states' in dir() and states['post_activations']:\n",
        "    # Get first batch, first sample\n",
        "    post_acts = states['post_activations'][0]  # (T, B, D)\n",
        "    T, B, D = post_acts.shape\n",
        "    \n",
        "    sample_idx = 0\n",
        "    activations = post_acts[:, sample_idx, :]  # (T, D)\n",
        "    \n",
        "    # Find most active neurons\n",
        "    neuron_variance = np.var(activations, axis=0)\n",
        "    top_neurons = np.argsort(neuron_variance)[-10:]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "    \n",
        "    # Heatmap of top neurons over time\n",
        "    im = axes[0].imshow(activations[:, top_neurons].T, aspect='auto', cmap='RdBu_r')\n",
        "    axes[0].set_xlabel('Tick (t)')\n",
        "    axes[0].set_ylabel('Neuron Index')\n",
        "    axes[0].set_title('Top 10 Most Variable Neurons Over Time')\n",
        "    axes[0].set_yticks(range(10))\n",
        "    axes[0].set_yticklabels(top_neurons)\n",
        "    plt.colorbar(im, ax=axes[0], label='Activation')\n",
        "    \n",
        "    # Line plot of individual neurons\n",
        "    for i, neuron_idx in enumerate(top_neurons[:5]):\n",
        "        axes[1].plot(activations[:, neuron_idx], label=f'Neuron {neuron_idx}', alpha=0.8)\n",
        "    \n",
        "    axes[1].set_xlabel('Tick (t)')\n",
        "    axes[1].set_ylabel('Activation')\n",
        "    axes[1].set_title('Activation Traces of Top 5 Neurons')\n",
        "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nModel has {D} neurons (d_model)\")\n",
        "    print(f\"Running for {T} internal ticks\")\n",
        "else:\n",
        "    print(\"No states collected yet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Place Cell Analysis\n",
        "\n",
        "Core question: Do specific neurons fire at specific maze positions?\n",
        "\n",
        "We'll compute a **spatial information score** for each neuron:\n",
        "- High score = neuron fires consistently at specific (x,y) locations\n",
        "- Low score = neuron fires uniformly regardless of position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trace_path(maze_img, solution):\n",
        "    \"\"\"Trace the solution path to get (row, col) positions.\"\"\"\n",
        "    # Find start (red pixel)\n",
        "    start_mask = (\n",
        "        (maze_img[:,:,0] > 0.9) & \n",
        "        (maze_img[:,:,1] < 0.1) & \n",
        "        (maze_img[:,:,2] < 0.1)\n",
        "    )\n",
        "    start_coords = np.argwhere(start_mask)\n",
        "    \n",
        "    if len(start_coords) == 0:\n",
        "        return []\n",
        "    \n",
        "    current_pos = list(start_coords[0])\n",
        "    positions = [tuple(current_pos)]\n",
        "    \n",
        "    # Direction mappings\n",
        "    deltas = {\n",
        "        0: (-1, 0),  # Up\n",
        "        1: (1, 0),   # Down\n",
        "        2: (0, -1),  # Left\n",
        "        3: (0, 1),   # Right\n",
        "        4: (0, 0),   # Wait\n",
        "    }\n",
        "    \n",
        "    for move in solution:\n",
        "        if move == 4:  # Wait/Stop\n",
        "            positions.append(tuple(current_pos))\n",
        "        else:\n",
        "            delta = deltas.get(int(move), (0, 0))\n",
        "            current_pos[0] += delta[0]\n",
        "            current_pos[1] += delta[1]\n",
        "            positions.append(tuple(current_pos))\n",
        "    \n",
        "    return positions\n",
        "\n",
        "if 'states' in dir() and states['post_activations']:\n",
        "    # Collect position-activation pairs\n",
        "    position_neuron_activations = defaultdict(lambda: defaultdict(list))\n",
        "    \n",
        "    for batch_idx in range(len(states['post_activations'])):\n",
        "        post_acts = states['post_activations'][batch_idx]  # (T, B, D)\n",
        "        mazes = states['mazes'][batch_idx]\n",
        "        solutions = states['solutions'][batch_idx]\n",
        "        \n",
        "        T, B, D = post_acts.shape\n",
        "        \n",
        "        for sample_idx in range(B):\n",
        "            positions = trace_path(mazes[sample_idx], solutions[sample_idx])\n",
        "            if not positions:\n",
        "                continue\n",
        "            \n",
        "            # Map ticks to positions\n",
        "            for t in range(T):\n",
        "                pos_idx = min(t * len(positions) // T, len(positions) - 1)\n",
        "                pos = positions[pos_idx]\n",
        "                \n",
        "                # Store activation for each neuron at this position\n",
        "                for neuron_idx in range(D):\n",
        "                    position_neuron_activations[pos][neuron_idx].append(\n",
        "                        post_acts[t, sample_idx, neuron_idx]\n",
        "                    )\n",
        "    \n",
        "    print(f\"Collected activations at {len(position_neuron_activations)} unique positions\")\n",
        "else:\n",
        "    print(\"No states collected yet.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'position_neuron_activations' in dir() and position_neuron_activations:\n",
        "    # Compute place cell scores for each neuron\n",
        "    D = len(list(position_neuron_activations.values())[0])  # Number of neurons\n",
        "    \n",
        "    neuron_scores = {}\n",
        "    neuron_peak_positions = {}\n",
        "    \n",
        "    for neuron_idx in tqdm(range(D), desc=\"Computing place cell scores\"):\n",
        "        pos_means = {}\n",
        "        pos_vars = {}\n",
        "        \n",
        "        for pos, neuron_acts in position_neuron_activations.items():\n",
        "            if neuron_idx in neuron_acts:\n",
        "                acts = neuron_acts[neuron_idx]\n",
        "                pos_means[pos] = np.mean(acts)\n",
        "                pos_vars[pos] = np.var(acts) if len(acts) > 1 else 0\n",
        "        \n",
        "        if pos_means:\n",
        "            spatial_variance = np.var(list(pos_means.values()))\n",
        "            within_variance = np.mean(list(pos_vars.values())) + 1e-6\n",
        "            \n",
        "            score = spatial_variance / within_variance\n",
        "            peak_pos = max(pos_means.keys(), key=lambda p: pos_means[p])\n",
        "            \n",
        "            neuron_scores[neuron_idx] = score\n",
        "            neuron_peak_positions[neuron_idx] = peak_pos\n",
        "    \n",
        "    # Rank neurons\n",
        "    ranked_neurons = sorted(neuron_scores.keys(), key=lambda n: neuron_scores[n], reverse=True)\n",
        "    \n",
        "    print(f\"\\nTop 10 Place Cell Neurons:\")\n",
        "    for i, n in enumerate(ranked_neurons[:10]):\n",
        "        print(f\"  {i+1}. Neuron {n}: score={neuron_scores[n]:.4f}, peak={neuron_peak_positions[n]}\")\n",
        "else:\n",
        "    print(\"No position data collected yet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualize Place Fields\n",
        "\n",
        "Create heatmaps showing where each top neuron fires strongest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'ranked_neurons' in dir() and ranked_neurons:\n",
        "    # Get maze size\n",
        "    maze_size = 39 if CONFIG['maze_size'] in ['small', 'medium'] else 99\n",
        "    \n",
        "    # Plot place fields for top neurons\n",
        "    top_n = min(12, len(ranked_neurons))\n",
        "    n_cols = 4\n",
        "    n_rows = (top_n + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 4*n_rows))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, neuron_idx in enumerate(ranked_neurons[:top_n]):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Create place field\n",
        "        place_field = np.zeros((maze_size, maze_size))\n",
        "        counts = np.zeros((maze_size, maze_size))\n",
        "        \n",
        "        for pos, neuron_acts in position_neuron_activations.items():\n",
        "            if neuron_idx in neuron_acts:\n",
        "                row, col = pos\n",
        "                if 0 <= row < maze_size and 0 <= col < maze_size:\n",
        "                    place_field[row, col] = np.mean(neuron_acts[neuron_idx])\n",
        "                    counts[row, col] = 1\n",
        "        \n",
        "        place_field = np.ma.masked_where(counts == 0, place_field)\n",
        "        \n",
        "        im = ax.imshow(place_field, cmap='hot', aspect='equal')\n",
        "        ax.set_title(f\"Neuron {neuron_idx}\\nScore: {neuron_scores[neuron_idx]:.2f}\")\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    \n",
        "    # Hide empty subplots\n",
        "    for idx in range(top_n, len(axes)):\n",
        "        axes[idx].set_visible(False)\n",
        "    \n",
        "    plt.suptitle('Place Fields: Neuron Activation vs. Maze Position', fontsize=14, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No ranking available yet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Next Steps\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "(To be filled after running the analysis)\n",
        "\n",
        "1. **Place Cell Candidates**: Neurons with high spatial selectivity scores\n",
        "2. **Spatial Coverage**: How well do the neurons cover the maze space?\n",
        "3. **Temporal Dynamics**: How does position encoding evolve over ticks?\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Teleport Experiment**: Patch position-encoding neurons to verify causal role\n",
        "2. **Cross-Maze Generalization**: Do the same neurons encode position across different mazes?\n",
        "3. **Synchronization Analysis**: How does $S_t$ relate to position encoding?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results if analysis was completed\n",
        "if 'ranked_neurons' in dir() and ranked_neurons:\n",
        "    output_dir = str(PROJECT_ROOT / 'experiments/interpretability/outputs')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    np.savez(\n",
        "        f\"{output_dir}/notebook_results.npz\",\n",
        "        ranked_neurons=ranked_neurons,\n",
        "        neuron_scores=dict(neuron_scores),\n",
        "        neuron_peak_positions=dict(neuron_peak_positions)\n",
        "    )\n",
        "    \n",
        "    print(f\"Results saved to: {output_dir}/notebook_results.npz\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
